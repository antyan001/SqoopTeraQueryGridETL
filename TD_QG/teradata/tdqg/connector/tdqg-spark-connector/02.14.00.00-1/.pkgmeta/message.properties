# Connector properties
server=Server
port=Port
security=Authentication Mechanism
linkBufferCount=Link Buffer Count
linkBufferSize=Link Buffer Size
linkHeartbeatInterval=Link Heartbeat Interval
linkHandshakeTimeout=Link Handshake Timeout
readTimeout=Read Timeout
writeTimeout=Write Timeout
responseTimeout=Response Timeout
importTimeout=Initiator Import Timeout 
tempDbName=Temporary Database Name
databaseName=Database Name
enableLogging=Enable Logging
defaultStringSize=Default String Size
defaultBinarySize=Default Binary Size
authUserName=Username
authPassword=Password
numExecutors=Number of Executors
confFilePaths=Conf File Paths
keytab=Keytab
hadoopProperties=Hadoop Properties
collectActivityCount=Collect Approximate Activity Count
disablePushdown=Disable Pushdown
compressionCodec=Compression Codec
connectionMaxIdleTime=Connection Max Idle Time
connectionPoolSize=Connection Pool Size
evictPeriodMin=Connection Evict Frequency
lobSupport = 16.20+ LOB Support
sparkHome=Spark Home Path
executionType=Spark Execution Mechanism
sslClientTrustStorePath=SSL TrustStore Path
sslClientTrustStorePassword=SSL TrustStore Password
queueName=Queue Name

# Connector property description
server.description=The hostname of Spark Thrift server
port.description=The port Spark Thrift server is listening on
security.description=The authentication mechanism used on the cluster
linkBufferCount.description=The maximum number of buffers to allocate per unit of parallelism
linkBufferSize.description=The size of the buffers to allocate
linkHeartbeatInterval.description=The interval between each heartbeat
linkHandshakeTimeout.description=The handshake timeout for the link channel setup
readTimeout.description=The timeout value for a read operation
writeTimeout.description=The timeout value for a write operation
responseTimeout.description=The timeout value for receiving a response
importTimeout.description=The timeout value for initiator import duration
tempDbName.description=The name of the temporary database
databaseName.description=The name of the database if not specified
enableLogging.description=The level of logging
defaultStringSize.description=The default character length of a String column
defaultBinarySize.description=The default size of a Binary column
authUserName.description=The name of the authorized user for security
authPassword.description=The password of the authorized user for security
numExecutors.description=The number of Executors to be used
confFilePaths.description=The paths to core-site.xml, hdfs-site.xml and hive-site.xml (comma-separated)
keytab.description=The keytab to use for Kerberos
hadoopProperties.description=Custom hadoop properties to override cluster configuration settings
collectActivityCount.description=Whether to collect Activity Count when exporting to Spark SQL (approximate if there are concurrent exports)
disablePushdown.description=Whether to disable predicate pushdown
compressionCodec.description=The compression codec to be used for export
connectionMaxIdleTime.description=The maximum idle time (seconds) that connection object can stay in the pool
connectionPoolSize.description=Connection pool size
evictPeriodMin.description=Connection pool evict frequency (minutes)
lobSupport.description=Whether to map STRING/BINARY columns to LOB on 16.20+ TDBMS
sparkHome.description=Path to the Spark home directory, which should contain a /jars sub-directory containing all Spark library JARs
executionType.description=Mechanism used by the target connector to submit queries to Spark
sslClientTrustStorePath.description=SSL truststore path on the connector nodes.  Overrides the default behavior of using the keystore information defined in the thrift server config.
sslClientTrustStorePassword.description=SSL truststore password on the connector nodes.
queueName.description=The name of the queue that submits Spark job (Spark Application mode only).

# Security enum names
security.NONE=None
security.KERBEROS=Kerberos

# enableLogging enum values
enableLogging.NONE=None
enableLogging.WARN=Warn
enableLogging.INFO=Info
enableLogging.DEBUG=Debug

# compressionCodec enum values
compressionCodec.None=System default
compressionCodec.Deflate=Deflate(org.apache.hadoop.io.compress.DefaultCodec)
compressionCodec.BZip2=BZip2(org.apache.hadoop.io.compress.BZip2Codec)
compressionCodec.Gzip=Gzip(org.apache.hadoop.io.compress.GzipCodec)
compressionCodec.LZ4=LZ4(org.apache.hadoop.io.compress.Lz4Codec)
compressionCodec.Snappy=Snappy(org.apache.hadoop.io.compress.SnappyCodec)

# Units
bytes=bytes
minutes=minutes
seconds=seconds
milliseconds=milliseconds
characters=characters

# executionType enum names
executionType.THRIFTSERVER=Spark Thrift Server
executionType.SPARK-SUBMIT=Spark Application

# Group and subgroup names
basic=Basic
securityGroup=Security
queryEngine=Query Engine
advanced=Advanced
ssl=Secure Sockets Layer (SSL)
fabric=Fabric
connectionPooling=Connection Pooling
