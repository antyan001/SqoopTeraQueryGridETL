{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/home/ektov1-av_ca-sbrf-ru/bin/python35\n",
    "import os\n",
    "import sys\n",
    "curruser = os.environ.get('USER')\n",
    "\n",
    "# sys.path.insert(0, '/opt/workspace/{user}/system/support_library/'.format(user=curruser))\n",
    "# sys.path.insert(0, '/opt/workspace/{user}/libs/'.format(user=curruser))\n",
    "# sys.path.insert(0, '/opt/workspace/{user}/system/labdata/lib/'.format(user=curruser))\n",
    "\n",
    "\n",
    "# sys.path.insert(0, './../src')\n",
    "sys.path.insert(0, '/opt/workspace/{user}/notebooks/support_library/'.format(user=curruser))\n",
    "sys.path.insert(0, '/opt/workspace/{user}/libs/python3.5/site-packages/'.format(user=curruser))\n",
    "sys.path.insert(0, '/opt/workspace/{user}/notebooks/labdata/lib/'.format(user=curruser))\n",
    "\n",
    "#import tendo.singleton\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='./__tera_fload__.log',level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from time import sleep\n",
    "from itertools import islice\n",
    "from multiprocessing import Pool, Process, JoinableQueue\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from functools import partial\n",
    "import subprocess\n",
    "from threading import Thread\n",
    "import time\n",
    "import decimal\n",
    "import datetime\n",
    "from getpass import getpass\n",
    "\n",
    "import jaydebeapi\n",
    "\n",
    "from transliterate import translit\n",
    "\n",
    "from spark_connector import SparkConnector\n",
    "from sparkdb_loader import spark\n",
    "from connector import OracleDB, TeraDB\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, HiveContext\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import loader as load\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sing = tendo.singleton.SingleInstance()\n",
    "\n",
    "# os.chdir('/opt/workspace/ektov1-av_ca-sbrf-ru/notebooks/Clickstream_Analytics/AutoUpdate/')\n",
    "# os.chdir('/opt/workspace/{}/notebooks/clickstream/AutoUpdate/'.format(curruser))\n",
    "\n",
    "\n",
    "##-----------------------------------------\n",
    "conn_schema = 'sbx_team_digitcamp' #'dl_t_team_ds_kb_sme' 'dl_t_team_speech_analytics'\n",
    "new_schema = 'dl_team_digitcamp'\n",
    "ga_schema = 'sklod_external_google_analytics'\n",
    "##-----------------------------------------\n",
    "\n",
    "\n",
    "def log(message, logger,\n",
    "        print_log : bool = True):\n",
    "    if not print_log:\n",
    "        return\n",
    "\n",
    "    logger.info(message)\n",
    "    print(message, file=sys.stdout)\n",
    "    # print(message, file=sys.stderr)\n",
    "\n",
    "def show(self, n=10):\n",
    "    return self.limit(n).toPandas()\n",
    "\n",
    "def typed_udf(return_type):\n",
    "    '''Make a UDF decorator with the given return type'''\n",
    "\n",
    "    def _typed_udf_wrapper(func):\n",
    "        return f.udf(func,return_type)\n",
    "\n",
    "def essense(channel: str, prod_cd: str):\n",
    "    message = \"{}: {} retargeting\".format(channel, prod_cd)\n",
    "    return message\n",
    "\n",
    "essense_udf = f.udf(essense, StringType())\n",
    "\n",
    "pyspark.sql.dataframe.DataFrame.show = show\n",
    "\n",
    "def print_and_log(message: str):\n",
    "    print(message)\n",
    "    logger.info(message)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_iterator(iterator,size):\n",
    "    \"\"\"\n",
    "    dest:\n",
    "        сервисная функция для итерации по блокам данных внутри RDD. \n",
    "        Чем больше size при увеличении количества потоков, тем быстрее обработка\n",
    "    args:\n",
    "        iterator-объект \n",
    "        size - размер элементов для единичной итерации\n",
    "    return:\n",
    "        вычисляемый объект bucket\n",
    " \n",
    "    \"\"\"\n",
    "    bucket = list()\n",
    "    for e in iterator:\n",
    "        bucket.append(e)\n",
    "        if len(bucket) >= size:\n",
    "            yield bucket\n",
    "            bucket = list()\n",
    "    if bucket:\n",
    "        yield bucket\n",
    "\n",
    "def block_classify(iterator):\n",
    "    import os\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    for out in block_iterator(iterator, 100):   \n",
    "\n",
    "        cols = [col for col,_ in col_bc.value]\n",
    "        currschema = StructType([StructField(col, typesmap_rdd_bc.value[col]) for col in cols])\n",
    "        sdf_proc = sp.sql.createDataFrame(out.collect(), schema=currschema)\n",
    "        break\n",
    "    \n",
    "    return sdf_proc\n",
    "\n",
    "def collectRowsByIndex(i, it, indxs):\n",
    "    out = []\n",
    "    if i in indxs:\n",
    "         out.extend(list(it)) #islice(it,0,5) \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Starting spark context. Run!\n",
      "2.4.0.cloudera2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "====================================================== 2022-03-30 ======================================================\n",
      "# __init__ : begin\n"
     ]
    }
   ],
   "source": [
    "print(\"### Starting spark context. Run!\")\n",
    "\n",
    "sp = spark(schema=conn_schema,\n",
    "           dynamic_alloc=False,\n",
    "           kerberos_auth=False,\n",
    "           numofinstances=8, \n",
    "           numofcores=8,\n",
    "           executor_memory='30g', \n",
    "           driver_memory='30g'\n",
    "           )\n",
    "hive = sp.sql\n",
    "\n",
    "print(sp.sc.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a Conection to Teradata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "TERADATA_HOST = \"TDSB15\"\n",
    "DB = \"\"\n",
    "USERNAME = \"\"\n",
    "PASSWORD = getpass()\n",
    "db = TeraDB(TERADATA_HOST, DB, USERNAME, PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get actual partitions from MetaStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_schema = 'sbx_t_team_cvm' #'sbx_team_digitcamp' #'sbx_t_team_cvm'\n",
    "table_name = 'lal_db_hist_out' #'ma_cmdm_ma_deal_new' #'lal_db_hist_in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "descr = hive.sql(\"describe extended {}.{}\".format(conn_schema,table_name)).collect()\n",
    "push_down = True\n",
    "loop_rows = cycle(descr)\n",
    "nextelem = next(loop_rows)\n",
    "while push_down:\n",
    "    thiselemen, nextelem = nextelem, next(loop_rows)\n",
    "    if nextelem.asDict()['col_name'] =='# Partition Information':\n",
    "        next(loop_rows)\n",
    "        part_col = next(loop_rows)\n",
    "        part_col_info = part_col.asDict()\n",
    "        push_down = False\n",
    "        \n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "part_name = part_col_info['col_name']\n",
    "# set the fix number of sorted patitions to catch from metastore\n",
    "numdays = 15       \n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "hasPartitioned = len([item.asDict() for item in descr if item.asDict()['col_name'] =='# Partition Information']) > 0\n",
    "if hasPartitioned:\n",
    "    try:\n",
    "        parts = hive.sql(\"show partitions {}.{}\".format(conn_schema,table_name)).collect()\n",
    "        parts = [part['partition'] for part in parts if not part['partition'].endswith('__HIVE_DEFAULT_PARTITION__')]\n",
    "        parts = sorted(parts,reverse=True)\n",
    "        max_part = parts[0]\n",
    "        extract_date=re.compile(\"\\d{4}\\-\\d{2}\\-\\d{2}\")\n",
    "        ext = extract_date.search(max_part)\n",
    "        try:\n",
    "            max_trunc_dt = ext.group(0)\n",
    "        except:\n",
    "            max_trunc_dt = None\n",
    "        if part_col_info['data_type'] in ('date', 'timestamp', 'string') and (max_trunc_dt is not None): \n",
    "            parts = sorted(parts, reverse=True, key=lambda x: \n",
    "                           datetime.datetime.strptime(x.split(part_name+'=')[-1].split('/')[0], '%Y-%m-%d'))\n",
    "        else:\n",
    "            parts = sorted(parts, reverse=True, key=lambda x: int(x.split(part_name+'=')[-1].split('/')[0]))\n",
    "        last_part_lst = sorted(list(set([part.split(part_name+'=')[-1].split('/')[0] for part in parts])), \n",
    "                               reverse=True)[:numdays]\n",
    "    except (AnalysisException, IndexError):\n",
    "        last_part_lst = None\n",
    "else:\n",
    "    last_part_lst = None\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE_DT_DAY'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-03-17',\n",
       " '2022-03-16',\n",
       " '2022-03-03',\n",
       " '2022-03-01',\n",
       " '2022-02-01',\n",
       " '2022-01-31',\n",
       " '2021-12-24',\n",
       " '2021-12-23',\n",
       " '2021-12-06',\n",
       " '2021-11-29',\n",
       " '2021-11-19',\n",
       " '2021-11-18',\n",
       " '2021-11-15',\n",
       " '2021-10-18',\n",
       " '2021-10-05']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_part_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Corrupted Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-03-17',\n",
       " '2022-03-16',\n",
       " '2022-03-03',\n",
       " '2022-03-01',\n",
       " '2022-02-01',\n",
       " '2022-01-31',\n",
       " '2021-12-24',\n",
       " '2021-12-23',\n",
       " '2021-12-06',\n",
       " '2021-11-29',\n",
       " '2021-11-19',\n",
       " '2021-11-18',\n",
       " '2021-11-15',\n",
       " '2021-10-18',\n",
       " '2021-10-05']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HDFS_PATH = \"hdfs://clsklsbx/user/team/{}/hive/{}/{}\".format(conn_schema.split(\"sbx_\")[-1].split(\"t_\")[-1], \n",
    "                                                             table_name, \n",
    "                                                             part_name)+\"={}/\"\n",
    "noncorrupCTL = []\n",
    "for ctl in last_part_lst:\n",
    "    try:\n",
    "        sdf = hive.read.load(path=HDFS_PATH.format(ctl), format='parquet').limit(10)\n",
    "        noncorrupCTL.append(ctl)\n",
    "    except (AnalysisException) as err:\n",
    "        if \"Unable to infer schema for Parquet\" in str(err):\n",
    "            print(\" Unable to infer schema for Parquet. It must be specified manually\")\n",
    "            \n",
    "noncorrupCTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Appropriate Rows Under User Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdf = hive.sql('''select * from {}.{} \n",
    "                  where {} between '{}' and '{}' '''.format(conn_schema,\n",
    "                                                            table_name,\n",
    "                                                            part_name.lower(),\n",
    "                                                            noncorrupCTL[-1],\n",
    "                                                            noncorrupCTL[0]\n",
    "                                                           )\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn(\"row_id\", f.monotonically_increasing_id().cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[INN: string, MODEL_NAME: string, HYPOTHESIS: string, CLIENT_TYPE: string, ID_SCEN: string, CREATE_DT: timestamp, ONLY_SB: decimal(20,0), DEAL_EVENT_DT: timestamp, MODEL_TYPE: string, TARGET: decimal(20,0), CREATE_DT_DAY: date, row_id: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477549"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INN</th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "      <th>CLIENT_TYPE</th>\n",
       "      <th>ID_SCEN</th>\n",
       "      <th>CREATE_DT</th>\n",
       "      <th>ONLY_SB</th>\n",
       "      <th>DEAL_EVENT_DT</th>\n",
       "      <th>MODEL_TYPE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CREATE_DT_DAY</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592012195609</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592012237030</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>592012345117</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>592012369679</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592012376965</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>592012426180</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>592012851219</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>592012888843</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>592013018634</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>592013084281</td>\n",
       "      <td>1-34DIS7P2</td>\n",
       "      <td>validation</td>\n",
       "      <td>all</td>\n",
       "      <td>test45</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31 11:42:11.301388</td>\n",
       "      <td>lal</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            INN  MODEL_NAME  HYPOTHESIS CLIENT_TYPE ID_SCEN  \\\n",
       "0  592012195609  1-34DIS7P2  validation         all  test45   \n",
       "1  592012237030  1-34DIS7P2  validation         all  test45   \n",
       "2  592012345117  1-34DIS7P2  validation         all  test45   \n",
       "3  592012369679  1-34DIS7P2  validation         all  test45   \n",
       "4  592012376965  1-34DIS7P2  validation         all  test45   \n",
       "5  592012426180  1-34DIS7P2  validation         all  test45   \n",
       "6  592012851219  1-34DIS7P2  validation         all  test45   \n",
       "7  592012888843  1-34DIS7P2  validation         all  test45   \n",
       "8  592013018634  1-34DIS7P2  validation         all  test45   \n",
       "9  592013084281  1-34DIS7P2  validation         all  test45   \n",
       "\n",
       "                   CREATE_DT ONLY_SB              DEAL_EVENT_DT MODEL_TYPE  \\\n",
       "0 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "1 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "2 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "3 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "4 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "5 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "6 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "7 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "8 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "9 2022-01-31 11:42:11.301388       0 2022-01-31 11:42:11.301388        lal   \n",
       "\n",
       "  TARGET CREATE_DT_DAY  row_id  \n",
       "0      1    2022-01-31       0  \n",
       "1      1    2022-01-31       1  \n",
       "2      1    2022-01-31       2  \n",
       "3      1    2022-01-31       3  \n",
       "4      1    2022-01-31       4  \n",
       "5      1    2022-01-31       5  \n",
       "6      1    2022-01-31       6  \n",
       "7      1    2022-01-31       7  \n",
       "8      1    2022-01-31       8  \n",
       "9      1    2022-01-31       9  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map ColumnTypes from Spark to Teradata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sdf.limit(1000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#**************************************************************************************************************\n",
    "#**************************************************************************************************************\n",
    "## Place Row_ID on the first column-position in your database. \n",
    "## Teradata always use the first column as Primary Index if not explicitly specified in \n",
    "## `INSERT INTO SELECT * FROM ` clause\n",
    "#**************************************************************************************************************\n",
    "#**************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE MULTISET TABLE {0}, \n",
      "    NO FALLBACK,\n",
      "    NO BEFORE JOURNAL, \n",
      "    NO AFTER JOURNAL,\n",
      "    CHECKSUM = DEFAULT,\n",
      "    DEFAULT MERGEBLOCKRATIO,\n",
      "    MAP = TD_MAP2\n",
      "    (\n",
      "        ROW_ID INTEGER,\n",
      "\tINN VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tMODEL_NAME VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tHYPOTHESIS VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tCLIENT_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tID_SCEN VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tCREATE_DT TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS',\n",
      "\tONLY_SB FLOAT,\n",
      "\tDEAL_EVENT_DT TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS',\n",
      "\tMODEL_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tTARGET FLOAT,\n",
      "\tCREATE_DT_DAY DATE FORMAT 'YYYY-MM-DD'\n",
      "\t)\n",
      "PRIMARY INDEX (ROW_ID);\n"
     ]
    }
   ],
   "source": [
    "cols_specific = {}\n",
    "cols_specific[\"ROW_ID\"] = ['INTEGER', 'INT']\n",
    "#cols_specific {COL_NAME: [TERATYPE, HIVE_TYPE]}\n",
    "\n",
    "isDateFmt = False\n",
    "PRIMARY_INDX = 'ROW_ID'\n",
    "\n",
    "str_ = \\\n",
    "'''\n",
    "CREATE MULTISET TABLE {0}, \n",
    "    NO FALLBACK,\n",
    "    NO BEFORE JOURNAL, \n",
    "    NO AFTER JOURNAL,\n",
    "    CHECKSUM = DEFAULT,\n",
    "    DEFAULT MERGEBLOCKRATIO,\n",
    "    MAP = TD_MAP2\n",
    "    (\n",
    "        ROW_ID INTEGER,\n",
    "'''\n",
    "for column_name, column in df.iteritems():\n",
    "    try:\n",
    "        if isinstance(column[column.first_valid_index()], str):\n",
    "            if (df[column_name].str.len().max() >= 4000) or ('COMMONSEGMENTOUID' in column_name.upper()):\n",
    "    #             df.drop(columns=[column_name], inplace=True)\n",
    "                str_+=column_name.upper() + ' ' +'CLOB, '\n",
    "                cols_specific[column_name] = ['CLOB', 'STRING']\n",
    "            else:\n",
    "                if 'INN' in column_name.upper() or 'KPP' in column_name.upper():\n",
    "                    str_+=\"\\t\" + column_name.upper() + ' ' +'VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC,\\n'\n",
    "                    cols_specific[column_name] = ['VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC', 'STRING']\n",
    "                elif part_name.upper() in column_name.upper():\n",
    "                    str_+=\"\\t\" + column_name.upper() + ' ' +\"DATE FORMAT 'YYYY-MM-DD',\\n\"\n",
    "                    cols_specific[column_name] = [\"DATE FORMAT 'YYYY-MM-DD'\", 'DATE_FORMAT({}, \"yyyy-MM-dd\")']\n",
    "                else:\n",
    "                    str_+=\"\\t\" + column_name.upper() + ' ' +'VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\n'\n",
    "                    cols_specific[column_name] = ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC', 'STRING']\n",
    "        elif isinstance(column[column.first_valid_index()], np.integer) and (column_name.upper() != \"ROW_ID\"):\n",
    "            if len(str(column[column.first_valid_index()])) < 1.e6:\n",
    "                str_+=\"\\t\" + column_name.upper() + ' ' +'INTEGER,\\n'\n",
    "                cols_specific[column_name] =['INTEGER', 'INT']\n",
    "            else:\n",
    "                str_+=\"\\t\" + column_name.upper() + ' ' +'INTEGER, '\n",
    "                cols_specific[column_name] =['INTEGER', 'BIGINT']            \n",
    "        elif (\n",
    "               ( isinstance(column[column.first_valid_index()], decimal.Decimal) ) or \n",
    "               ( isinstance(column[column.first_valid_index()], float) )\n",
    "             ):\n",
    "    #         df[column_name] = df[column_name].fillna(0.0)\n",
    "            str_+=\"\\t\" + column_name.upper() + ' ' +'FLOAT,\\n' \n",
    "            cols_specific[column_name] = ['FLOAT', 'FLOAT']\n",
    "        elif (\n",
    "                isinstance(column[column.first_valid_index()], pd.Timestamp) or \n",
    "                isinstance(column[column.first_valid_index()], datetime.date)\n",
    "             ):\n",
    "            if hasattr(column[column.first_valid_index()],'minute'):\n",
    "                if column[column.first_valid_index()].minute == 0:\n",
    "                    isDateFmt = True\n",
    "                elif column[column.first_valid_index()].microsecond != 0:\n",
    "                    isDateFmt = False\n",
    "                    str_+=\"\\t\" + column_name.upper() + ' ' +\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS.S(6)',\\n\"\n",
    "                    cols_specific[column_name] = [\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS.S(6)'\", \n",
    "                                                  'DATE_FORMAT({}, \"yyyy-MM-dd HH:mm:ss.SSSSSS\")']                    \n",
    "                else:\n",
    "                    isDateFmt = False\n",
    "                    str_+=\"\\t\" + column_name.upper() + ' ' +\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS',\\n\"\n",
    "                    cols_specific[column_name] = [\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS'\", \n",
    "                                                  'DATE_FORMAT({}, \"yyyy-MM-dd HH:mm:ss\")']\n",
    "            else:\n",
    "                isDateFmt = True\n",
    "            if isDateFmt:\n",
    "                str_+=\"\\t\" + column_name.upper() + ' ' +\"DATE FORMAT 'YYYY-MM-DD',\\n\"\n",
    "                cols_specific[column_name] = [\"DATE FORMAT 'YYYY-MM-DD'\", 'DATE_FORMAT({}, \"yyyy-MM-dd\")']            \n",
    "        else:\n",
    "            None  \n",
    "    except:\n",
    "        str_+=column_name.upper() + ' ' +'VARCHAR(800),\\n'\n",
    "        cols_specific[column_name] = ['VARCHAR(800)', 'STRING']\n",
    "        \n",
    "res=str_.strip()[:-1] + '\\n\\t)' + '\\nPRIMARY INDEX ({});'.format(PRIMARY_INDX)\n",
    "\n",
    "cr_tbl_sql = res\n",
    "\n",
    "print(cr_tbl_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Partitioning Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PART_COL_NAME = part_name\n",
    "cr_part_tbl_query = cr_tbl_sql[:-1] + \\\n",
    "\"\\nPARTITION BY RANGE_N({} BETWEEN DATE '2020-01-01' AND DATE '2025-01-01' EACH INTERVAL '1' DAY);\".format(PART_COL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE MULTISET TABLE {0}, \n",
      "    NO FALLBACK,\n",
      "    NO BEFORE JOURNAL, \n",
      "    NO AFTER JOURNAL,\n",
      "    CHECKSUM = DEFAULT,\n",
      "    DEFAULT MERGEBLOCKRATIO,\n",
      "    MAP = TD_MAP2\n",
      "    (\n",
      "        ROW_ID INTEGER,\n",
      "\tINN VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tMODEL_NAME VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tHYPOTHESIS VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tCLIENT_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tID_SCEN VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tCREATE_DT TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS',\n",
      "\tONLY_SB FLOAT,\n",
      "\tDEAL_EVENT_DT TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS',\n",
      "\tMODEL_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
      "\tTARGET FLOAT,\n",
      "\tCREATE_DT_DAY DATE FORMAT 'YYYY-MM-DD'\n",
      "\t)\n",
      "PRIMARY INDEX (ROW_ID)\n",
      "PARTITION BY RANGE_N(CREATE_DT_DAY BETWEEN DATE '2020-01-01' AND DATE '2025-01-01' EACH INTERVAL '1' DAY);\n"
     ]
    }
   ],
   "source": [
    "print(cr_part_tbl_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLIENT_TYPE': ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC',\n",
       "  'STRING'],\n",
       " 'CREATE_DT': [\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS'\",\n",
       "  'DATE_FORMAT({}, \"yyyy-MM-dd HH:mm:ss\")'],\n",
       " 'CREATE_DT_DAY': [\"DATE FORMAT 'YYYY-MM-DD'\",\n",
       "  'DATE_FORMAT({}, \"yyyy-MM-dd\")'],\n",
       " 'DEAL_EVENT_DT': [\"TIMESTAMP FORMAT 'YYYY-MM-DDBHH:MI:SS'\",\n",
       "  'DATE_FORMAT({}, \"yyyy-MM-dd HH:mm:ss\")'],\n",
       " 'HYPOTHESIS': ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC',\n",
       "  'STRING'],\n",
       " 'ID_SCEN': ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC', 'STRING'],\n",
       " 'INN': ['VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC', 'STRING'],\n",
       " 'MODEL_NAME': ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC',\n",
       "  'STRING'],\n",
       " 'MODEL_TYPE': ['VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC',\n",
       "  'STRING'],\n",
       " 'ONLY_SB': ['FLOAT', 'FLOAT'],\n",
       " 'ROW_ID': ['INTEGER', 'INT'],\n",
       " 'TARGET': ['FLOAT', 'FLOAT']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Exporting to Local storage of Hive tbl using RDD MapPartitions with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ROW_ID',\n",
       " 'INN',\n",
       " 'MODEL_NAME',\n",
       " 'HYPOTHESIS',\n",
       " 'CLIENT_TYPE',\n",
       " 'ID_SCEN',\n",
       " 'CREATE_DT',\n",
       " 'ONLY_SB',\n",
       " 'DEAL_EVENT_DT',\n",
       " 'MODEL_TYPE',\n",
       " 'TARGET',\n",
       " 'CREATE_DT_DAY']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLS_ORDER_LST__ = [\"ROW_ID\"] + [col.upper() for col in sdf.columns if col not in (\"row_id\")]\n",
    "COLS_ORDER_LST__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SPLIT__ = 2\n",
    "numPartitions = sdf.rdd.getNumPartitions()\n",
    "\n",
    "batches = np.array_split(np.arange(0, numPartitions), BATCH_SPLIT__)\n",
    "tuple_batches = [(i, batches[i]) for i in range(len(batches))]\n",
    "\n",
    "name_postfix , partitions = tuple_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLIENT_TYPE': StringType,\n",
       " 'CREATE_DT': TimestampType,\n",
       " 'CREATE_DT_DAY': DateType,\n",
       " 'DEAL_EVENT_DT': TimestampType,\n",
       " 'HYPOTHESIS': StringType,\n",
       " 'ID_SCEN': StringType,\n",
       " 'INN': StringType,\n",
       " 'MODEL_NAME': StringType,\n",
       " 'MODEL_TYPE': StringType,\n",
       " 'ONLY_SB': DecimalType(20,0),\n",
       " 'TARGET': DecimalType(20,0),\n",
       " 'row_id': IntegerType}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typesmap_rdd={}\n",
    "\n",
    "for column_name, column in sdf.dtypes:\n",
    "    if column == 'string':\n",
    "        typesmap_rdd[column_name] = StringType()\n",
    "    elif 'decimal' in column:\n",
    "        digits = int('{}'.format(column.split('(')[1].split(',')[0]))\n",
    "        prec   = int('{}'.format(column.split('(')[1].split(',')[1][:-1]))\n",
    "        typesmap_rdd[column_name] = DecimalType(digits,prec)\n",
    "    elif column == 'double':\n",
    "        typesmap_rdd[column_name] = DoubleType()        \n",
    "    elif column == 'float':\n",
    "        typesmap_rdd[column_name] = FloatType()\n",
    "    elif column == 'int':\n",
    "        typesmap_rdd[column_name] = IntegerType()       \n",
    "    elif column == 'bigint':\n",
    "        typesmap_rdd[column_name] = LongType()\n",
    "    elif column == 'timestamp':\n",
    "        typesmap_rdd[column_name] = TimestampType()\n",
    "    elif column == 'date':\n",
    "        typesmap_rdd[column_name] = DateType()\n",
    "        \n",
    "typesmap_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/workspace/ektov1-av_ca-sbrf-ru/notebooks/TERA_FAST_LOAD/csv'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_tbl_name = \"tmp_hive2tera_cast\"\n",
    "EXPORT_PATH = \"/opt/workspace/{curruser}/notebooks/TERA_FAST_LOAD/csv\".format(curruser = os.environ.get('USER'))\n",
    "EXPORT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b016f3cdbc544d39237603b51cac2a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Step 0; part length: 9\n",
      "# Step 1; part length: 8\n",
      "\n",
      "CPU times: user 4min 50s, sys: 14.5 s, total: 5min 5s\n",
      "Wall time: 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cols = [col for col,_ in sdf.dtypes]\n",
    "for i, partlst in tqdm_notebook(tuple_batches[:]):\n",
    "        \n",
    "    print(\"# Step {}; part length: {}\".format(i, len(partlst)))\n",
    "    res = sdf.rdd.mapPartitionsWithIndex(lambda i,it: collectRowsByIndex(i,it,indxs=partlst))\n",
    "    \n",
    "    currschema = StructType([StructField(col, typesmap_rdd[col]) for col in cols])\n",
    "    sdf_proc = hive.createDataFrame(res, schema=currschema)\n",
    "    \n",
    "    sdf_proc.registerTempTable(tmp_tbl_name)\n",
    "\n",
    "    _str = '''SELECT '''\n",
    "    for col_name, spec in cols_specific.items(): \n",
    "        if '{' not in spec[1]:\n",
    "            _str+='''CAST({col} AS {type}) {col}, '''.format(col=col_name, type=spec[1])\n",
    "        else:\n",
    "            _str+='''CAST({} as {}) {}, '''.format(spec[1].format(col_name), \n",
    "                                                   spec[0].split(\"FORMAT\")[0].split(\" \")[0].strip(), col_name)\n",
    "    fin_query = _str.strip()[:-1] + \" FROM {}\".format(tmp_tbl_name)\n",
    "\n",
    "    sdf_casted = hive.sql(fin_query)\n",
    "    sdf_casted = sdf_casted.select( [\"row_id\"]+[col for col in sdf.columns if col not in (\"row_id\")])    \n",
    "    \n",
    "    df = sdf_casted.toPandas()\n",
    "    df.to_csv(os.path.join(EXPORT_PATH, \"{}_{}.csv\".format(table_name, i)), sep=\",\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE Config for FastLoad utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_str=''\n",
    "\n",
    "config_str+=\\\n",
    "'''\n",
    "logon {HOST}/{user}, {_pass};\n",
    "\n",
    "set record vartext  \",\";\n",
    "record 2;\n",
    "\n",
    "database {db};\n",
    "drop table {db}.{tbl}_err;\n",
    "drop table {db}.{tbl}_err1;\n",
    "drop table {db}.{tbl}_err2;\n",
    "drop table {db}.{tbl};\n",
    "\n",
    "'''.format(HOST = TERADATA_HOST,\n",
    "           user = USERNAME,\n",
    "           _pass = PASSWORD,\n",
    "           db   = DB,\n",
    "           tbl  = table_name\n",
    "          )\n",
    "\n",
    "config_str+=cr_part_tbl_query.format(table_name)\n",
    "\n",
    "config_str+=\\\n",
    "'''\n",
    "create error table {db}.{tbl}_err for {db}.{tbl};\n",
    "begin loading {db}.{tbl}\n",
    "    errorfiles {db}.{tbl}_err1, {db}.{tbl}_err2\n",
    "    checkpoint 1500000;\n",
    "\n",
    "define\n",
    "\n",
    "'''.format(\n",
    "           db   = DB,\n",
    "           tbl  = table_name\n",
    "          )\n",
    "\n",
    "in_str=\"\"\n",
    "for col in COLS_ORDER_LST__:\n",
    "    in_str+=\"in_{} (VARCHAR(500)),\\n\".format(col)\n",
    "in_str=in_str.strip()[:-1]\n",
    "\n",
    "config_str+=in_str\n",
    "\n",
    "config_str+=\\\n",
    "'''\n",
    "\n",
    "file=\"U:\\FAST_LOAD\\csv\\lal_db_hist_in_0.csv\";\n",
    "\n",
    "SHOW;\n",
    "\n",
    "insert into {db}.{tbl} (\n",
    "\n",
    "'''.format(db=DB,\n",
    "           tbl=table_name\n",
    "          )\n",
    "\n",
    "in_str=\"\"\n",
    "for col in COLS_ORDER_LST__:\n",
    "    in_str+=\"{},\\n\".format(col)\n",
    "in_str=in_str.strip()[:-1]\n",
    "\n",
    "config_str+=in_str\n",
    "\n",
    "config_str+=\\\n",
    "'''\n",
    "\n",
    ")\n",
    "\n",
    "values (\n",
    "\n",
    "'''\n",
    " \n",
    "in_str=\"\"\n",
    "for col in COLS_ORDER_LST__:\n",
    "    _type = cols_specific[col]\n",
    "    if 'FORMAT' in _type[0]:\n",
    "        fmt = _type[0].split(\"FORMAT\")[-1].strip()\n",
    "        in_str+=\":in_{}(FORMAT {}),\\n\".format(col, fmt)\n",
    "    else:\n",
    "        in_str+=\":in_{},\\n\".format(col)\n",
    "in_str=in_str.strip()[:-1]\n",
    "\n",
    "config_str+=in_str    \n",
    "\n",
    "config_str+=\\\n",
    "'''\n",
    "\n",
    ");\n",
    "\n",
    "end loading;\n",
    "logoff;\n",
    "'''    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CONFIG into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONF_OUT_PATH__ = \"/opt/workspace/{curruser}/notebooks/TERA_FAST_LOAD/run.fld\".format(curruser = os.environ.get('USER'))\n",
    "\n",
    "with open(CONF_OUT_PATH__, \"w\", encoding=\"utf8\") as fout:\n",
    "#     for ind, line in enumerate(config_str.split(\"\\n\")):\n",
    "    fout.writelines(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "## Copy the content of current `/opt/workspace/../TERA_FAST_LOAD` folder into VARM disk `U:\\FAST_LOAD\\`\n",
    "## CHDIR -D U:\\FAST_LOAD\\\n",
    "## run teradata loader via executing command: `fastload -c utf8 <run.fld> log.txt`\n",
    "#######################################################################################################\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the state of the tbl being exported via FastLoad utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JDBC_ARGUMENTS = \"LOGMECH=LDAP, CHARSET=UTF8, TYPE=FASTEXPORT, COLUMN_NAME=ON, MAYBENULL=ON\"\n",
    "#DB = 'PRD_DB_CLIENT4D_DEV1'\n",
    "conn = jaydebeapi.connect(\n",
    "    jclassname=\"com.teradata.jdbc.TeraDriver\",\n",
    "    url=\"jdbc:teradata://{}/database={} , {}\".format(TERADATA_HOST, DB, JDBC_ARGUMENTS),\n",
    "    driver_args={\"user\": USERNAME, \"password\": PASSWORD},\n",
    "    jars=['/home/ektov1-av_ca-sbrf-ru/notebooks/drivers/tdgssconfig.jar',\n",
    "          '/home/ektov1-av_ca-sbrf-ru/notebooks/drivers/terajdbc4.jar']\n",
    ")\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"CREATE MULTISET TABLE PRD_DB_CLIENT4D_DEV1.lal_db_hist_in ,NO FALLBACK ,\\r     NO BEFORE JOURNAL,\\r     NO AFTER JOURNAL,\\r     CHECKSUM = DEFAULT,\\r     DEFAULT MERGEBLOCKRATIO,\\r     MAP = TD_MAP2\\r     (\\r      ROW_ID INTEGER,\\r      INN VARCHAR(20) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      MODEL_NAME VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      HYPOTHESIS VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      CLIENT_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      ID_SCEN VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      CREATE_DT TIMESTAMP(6) FORMAT 'YYYY-MM-DDBHH:MI:SS',\\r      ONLY_SB FLOAT,\\r      DEAL_EVENT_DT TIMESTAMP(6) FORMAT 'YYYY-MM-DDBHH:MI:SS',\\r      MODEL_TYPE VARCHAR(800) CHARACTER SET UNICODE NOT CASESPECIFIC,\\r      TARGET FLOAT,\\r      CREATE_DT_DAY DATE FORMAT 'YYYY-MM-DD')\\rPRIMARY INDEX ( ROW_ID )\\rPARTITION BY RANGE_N(CREATE_DT_DAY  BETWEEN DATE '2020-01-01' AND DATE '2025-01-01' EACH INTERVAL '1' DAY );\",)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curs.execute(\"SHOW TABLE PRD_DB_CLIENT4D_DEV1.{};\".format(table_name))\n",
    "curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_sql = '''SELECT TOP 1 \n",
    "                 *    \n",
    "             FROM PRD_DB_CLIENT4D_DEV1.{}\n",
    "             --WHERE CREATE_DT_DAY = '2021-10-18'\n",
    "         '''.format(table_name)\n",
    "\n",
    "curs.execute(my_sql)\n",
    "cols = [desc[0] for desc in curs.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>INN</th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "      <th>CLIENT_TYPE</th>\n",
       "      <th>ID_SCEN</th>\n",
       "      <th>CREATE_DT</th>\n",
       "      <th>ONLY_SB</th>\n",
       "      <th>DEAL_EVENT_DT</th>\n",
       "      <th>MODEL_TYPE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CREATE_DT_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1113</td>\n",
       "      <td>7810245481</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7889</td>\n",
       "      <td>261005469112</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9721</td>\n",
       "      <td>280118502932</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9862</td>\n",
       "      <td>500305708289</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1565</td>\n",
       "      <td>6664013640</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>993</td>\n",
       "      <td>770802303187</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1687</td>\n",
       "      <td>772740007083</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3525</td>\n",
       "      <td>7714928492</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4358</td>\n",
       "      <td>230302628903</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1914</td>\n",
       "      <td>343659106939</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7723</td>\n",
       "      <td>990116166600</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5870</td>\n",
       "      <td>505400553274</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3050</td>\n",
       "      <td>7826032175</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4987</td>\n",
       "      <td>231214690358</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2587</td>\n",
       "      <td>352600217489</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8888</td>\n",
       "      <td>772339149508</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6047</td>\n",
       "      <td>741512738830</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9965</td>\n",
       "      <td>6383004287</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3321</td>\n",
       "      <td>503625120332</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1706</td>\n",
       "      <td>7727498590</td>\n",
       "      <td>1-290ZX5NB</td>\n",
       "      <td>validation</td>\n",
       "      <td>ksb</td>\n",
       "      <td>test35</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-10-18 13:54:44</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-10-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROW_ID           INN  MODEL_NAME  HYPOTHESIS CLIENT_TYPE ID_SCEN  \\\n",
       "0     1113    7810245481  1-290ZX5NB  validation         ksb  test35   \n",
       "1     7889  261005469112  1-290ZX5NB  validation         ksb  test35   \n",
       "2     9721  280118502932  1-290ZX5NB  validation         ksb  test35   \n",
       "3     9862  500305708289  1-290ZX5NB  validation         ksb  test35   \n",
       "4     1565    6664013640  1-290ZX5NB  validation         ksb  test35   \n",
       "5      993  770802303187  1-290ZX5NB  validation         ksb  test35   \n",
       "6     1687  772740007083  1-290ZX5NB  validation         ksb  test35   \n",
       "7     3525    7714928492  1-290ZX5NB  validation         ksb  test35   \n",
       "8     4358  230302628903  1-290ZX5NB  validation         ksb  test35   \n",
       "9     1914  343659106939  1-290ZX5NB  validation         ksb  test35   \n",
       "10    7723  990116166600  1-290ZX5NB  validation         ksb  test35   \n",
       "11    5870  505400553274  1-290ZX5NB  validation         ksb  test35   \n",
       "12    3050    7826032175  1-290ZX5NB  validation         ksb  test35   \n",
       "13    4987  231214690358  1-290ZX5NB  validation         ksb  test35   \n",
       "14    2587  352600217489  1-290ZX5NB  validation         ksb  test35   \n",
       "15    8888  772339149508  1-290ZX5NB  validation         ksb  test35   \n",
       "16    6047  741512738830  1-290ZX5NB  validation         ksb  test35   \n",
       "17    9965    6383004287  1-290ZX5NB  validation         ksb  test35   \n",
       "18    3321  503625120332  1-290ZX5NB  validation         ksb  test35   \n",
       "19    1706    7727498590  1-290ZX5NB  validation         ksb  test35   \n",
       "\n",
       "              CREATE_DT  ONLY_SB        DEAL_EVENT_DT MODEL_TYPE  TARGET  \\\n",
       "0   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "1   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "2   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "3   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "4   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "5   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "6   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "7   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "8   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "9   2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "10  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "11  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "12  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "13  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "14  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "15  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "16  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "17  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "18  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "19  2021-10-18 13:54:44      0.0  2021-10-18 13:54:44        lal     1.0   \n",
       "\n",
       "   CREATE_DT_DAY  \n",
       "0     2021-10-18  \n",
       "1     2021-10-18  \n",
       "2     2021-10-18  \n",
       "3     2021-10-18  \n",
       "4     2021-10-18  \n",
       "5     2021-10-18  \n",
       "6     2021-10-18  \n",
       "7     2021-10-18  \n",
       "8     2021-10-18  \n",
       "9     2021-10-18  \n",
       "10    2021-10-18  \n",
       "11    2021-10-18  \n",
       "12    2021-10-18  \n",
       "13    2021-10-18  \n",
       "14    2021-10-18  \n",
       "15    2021-10-18  \n",
       "16    2021-10-18  \n",
       "17    2021-10-18  \n",
       "18    2021-10-18  \n",
       "19    2021-10-18  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sql = '''SELECT TOP 1000 \n",
    "                 *    \n",
    "             FROM PRD_DB_CLIENT4D_DEV1.{}\n",
    "             --WHERE CREATE_DT_DAY = '2021-10-18'\n",
    "         '''.format(table_name)\n",
    "curs.execute(my_sql)\n",
    "\n",
    "res = pd.DataFrame(curs.fetchall(), columns=cols)\n",
    "\n",
    "res.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PySpark backened with jDBC driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_sql = '''(SELECT TOP 100 \n",
    "                 *\n",
    "             FROM {db}.{tbl}) as t\n",
    "         '''.format(db=DB, tbl = table_name )\n",
    "\n",
    "sdf = sp.get_teradata(db, my_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ROW_ID', 'int'),\n",
       " ('INN', 'string'),\n",
       " ('MODEL_NAME', 'string'),\n",
       " ('HYPOTHESIS', 'string'),\n",
       " ('CLIENT_TYPE', 'string'),\n",
       " ('ID_SCEN', 'string'),\n",
       " ('CREATE_DT', 'timestamp'),\n",
       " ('ONLY_SB', 'float'),\n",
       " ('DEAL_EVENT_DT', 'timestamp'),\n",
       " ('MODEL_TYPE', 'string'),\n",
       " ('TARGET', 'float'),\n",
       " ('CREATE_DT_DAY', 'date')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>INN</th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>HYPOTHESIS</th>\n",
       "      <th>CLIENT_TYPE</th>\n",
       "      <th>ID_SCEN</th>\n",
       "      <th>CREATE_DT</th>\n",
       "      <th>ONLY_SB</th>\n",
       "      <th>DEAL_EVENT_DT</th>\n",
       "      <th>MODEL_TYPE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CREATE_DT_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78692</td>\n",
       "      <td>861204106102</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139113</td>\n",
       "      <td>3249003661</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229857</td>\n",
       "      <td>7325101364</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64050</td>\n",
       "      <td>6317104240</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153978</td>\n",
       "      <td>0256014475</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131302</td>\n",
       "      <td>164491236155</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41353</td>\n",
       "      <td>5834115946</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>125510</td>\n",
       "      <td>3241501190</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10948</td>\n",
       "      <td>5404342739</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>222555</td>\n",
       "      <td>7716805016</td>\n",
       "      <td>1-115HHZO</td>\n",
       "      <td>original dataset</td>\n",
       "      <td>all</td>\n",
       "      <td>test38</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-11-19 13:14:33</td>\n",
       "      <td>lal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID           INN MODEL_NAME        HYPOTHESIS CLIENT_TYPE ID_SCEN  \\\n",
       "0   78692  861204106102  1-115HHZO  original dataset         all  test38   \n",
       "1  139113    3249003661  1-115HHZO  original dataset         all  test38   \n",
       "2  229857    7325101364  1-115HHZO  original dataset         all  test38   \n",
       "3   64050    6317104240  1-115HHZO  original dataset         all  test38   \n",
       "4  153978    0256014475  1-115HHZO  original dataset         all  test38   \n",
       "5  131302  164491236155  1-115HHZO  original dataset         all  test38   \n",
       "6   41353    5834115946  1-115HHZO  original dataset         all  test38   \n",
       "7  125510    3241501190  1-115HHZO  original dataset         all  test38   \n",
       "8   10948    5404342739  1-115HHZO  original dataset         all  test38   \n",
       "9  222555    7716805016  1-115HHZO  original dataset         all  test38   \n",
       "\n",
       "            CREATE_DT  ONLY_SB       DEAL_EVENT_DT MODEL_TYPE  TARGET  \\\n",
       "0 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "1 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "2 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "3 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "4 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "5 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "6 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "7 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "8 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "9 2021-11-19 13:14:33      0.0 2021-11-19 13:14:33        lal     1.0   \n",
       "\n",
       "  CREATE_DT_DAY  \n",
       "0    2021-11-19  \n",
       "1    2021-11-19  \n",
       "2    2021-11-19  \n",
       "3    2021-11-19  \n",
       "4    2021-11-19  \n",
       "5    2021-11-19  \n",
       "6    2021-11-19  \n",
       "7    2021-11-19  \n",
       "8    2021-11-19  \n",
       "9    2021-11-19  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
